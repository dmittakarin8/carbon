# ğŸ—ï¸ **COMPREHENSIVE ARCHITECTURAL REVIEW**
## **Branch:** `feature/pipeline-architecture`
## **Date:** 2025-11-14
## **Reviewer:** Architectural Analysis Agent

---

## **EXECUTIVE SUMMARY**

This branch implements a **"Phase 4 Activation Layer"** that creates a completely parallel analytics pipeline alongside the existing legacy JSONL-based aggregator system. The architecture introduces 4,263 new lines of code across 11 pipeline modules, adding a dual-channel streaming mechanism where all four streamers (PumpSwap, BonkSwap, Moonshot, Jupiter DCA) simultaneously write to:

1. **Legacy JSONL files** (existing behavior, preserved)
2. **New pipeline channel** (new behavior, optional via `try_send`)

The pipeline ingests trades via an in-memory channel, computes rolling-window aggregates (60s/300s/900s), detects trading signals (BREAKOUT, SURGE, FOCUSED, BOT_DROPOFF), and writes results to SQLite.

**Critical Finding:** The system is **architecturally sound but functionally incomplete**. The business goal of "DCA + volume correlation for conviction signals" is **not implemented** in this branchâ€”DCA trades flow through the pipeline but are never correlated with PumpSwap/BonkSwap/Moonshot activity.

---

## **A. REPOSITORY-WIDE ARCHITECTURAL SUMMARY**

### **1. Component Inventory**

#### **Modified/New Files (22 files, 4,783 insertions)**

| File | Lines | Purpose | Status |
|------|-------|---------|--------|
| `src/bin/pipeline_runtime.rs` | 171 | Pipeline orchestrator binary | âœ… Complete |
| `src/pipeline/engine.rs` | 602 | Orchestrates rolling state & signal detection | âœ… Complete |
| `src/pipeline/state.rs` | 1128 | Rolling window state management | âœ… Complete |
| `src/pipeline/types.rs` | 467 | Data structures (TradeEvent, AggregatedTokenState, etc.) | âœ… Complete |
| `src/pipeline/ingestion.rs` | 258 | Channel receiver â†’ engine â†’ DB writer | âœ… Complete |
| `src/pipeline/db.rs` | 709 | SQLite writer trait + implementation | âœ… Complete |
| `src/pipeline/signals.rs` | 116 | Signal type definitions | âœ… Complete |
| `src/pipeline/scheduler.rs` | 158 | Periodic flush scheduler | âš ï¸ Price/metadata schedulers stubbed |
| `src/pipeline/config.rs` | 117 | Environment variable loading | âœ… Complete |
| `src/pipeline/windows.rs` | 206 | Rolling time window abstraction | âš ï¸ Unused (dead code) |
| `src/pipeline/blocklist.rs` | 81 | Blocklist trait (unimplemented) | âŒ Stub only |
| `src/pipeline/mod.rs` | 88 | Module exports | âœ… Complete |
| `src/streamer_core/lib.rs` | +55 | **Dual-channel logic added** | âœ… Complete |
| `tests/test_dual_channel_streamer.rs` | 270 | Dual-channel integration test | âœ… Complete |

#### **SQL Schema (5 tables)**

| Table | Purpose | Writer | Reader |
|-------|---------|--------|--------|
| `token_metadata` | Token info (symbol, decimals) | Metadata fetchers | Pipeline engine |
| `mint_blocklist` | Blocked tokens | Admin | Signal writer (blocklist check) |
| `token_aggregates` | **Rolling metrics** (60s/300s/900s) | **Pipeline ingestion** | UIs, dashboards |
| `token_signals` | **Append-only signals** (BREAKOUT, SURGE) | **Pipeline ingestion** | UIs, dashboards |
| `system_metrics` | System health | Optional | Optional |

---

### **2. Data Flow Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Yellowstone gRPC Stream                       â”‚
â”‚                  (Solana blockchain transactions)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              4 Streamer Binaries (Carbon Pipelines)               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ PumpSwap â”‚ BonkSwap â”‚ Moonshot â”‚ Jupiter DCA          â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                    â”‚
â”‚   Each streamer:                                                   â”‚
â”‚   1. Extracts trades from TransactionStatusMeta                   â”‚
â”‚   2. Writes TradeEvent to JSONL (legacy path)      â† BLOAT SOURCE â”‚
â”‚   3. try_send() TradeEvent to pipeline channel     â† NEW PATH     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                                         â”‚
               â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEGACY PATH (JSONL files)   â”‚      â”‚  NEW PATH (Pipeline)          â”‚
â”‚  - streams/pumpswap/*.jsonl  â”‚      â”‚  - mpsc channel (10k buffer)  â”‚
â”‚  - streams/bonkswap/*.jsonl  â”‚      â”‚  - Non-blocking try_send()    â”‚
â”‚  - streams/moonshot/*.jsonl  â”‚      â”‚  - Drops trades if full       â”‚
â”‚  - streams/jupiter_dca/*.jsonlâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                               â”‚                   â”‚
â”‚  Files grow indefinitely      â”‚                   â–¼
â”‚  (rotation not active)        â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               â”‚      â”‚  PipelineEngine (in-memory)   â”‚
â”‚  âŒ CAUSING DATABASE BLOAT    â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚ Per-token rolling state â”‚  â”‚
                                        â”‚  â”‚ HashMap<Mint, State>    â”‚  â”‚
                                        â”‚  â”‚                         â”‚  â”‚
                                        â”‚  â”‚ Windows:                â”‚  â”‚
                                        â”‚  â”‚  - trades_60s: Vec      â”‚  â”‚
                                        â”‚  â”‚  - trades_300s: Vec     â”‚  â”‚
                                        â”‚  â”‚  - trades_900s: Vec     â”‚  â”‚
                                        â”‚  â”‚                         â”‚  â”‚
                                        â”‚  â”‚ On each trade:          â”‚  â”‚
                                        â”‚  â”‚  1. Push to vectors     â”‚  â”‚
                                        â”‚  â”‚  2. Evict old trades    â”‚  â”‚
                                        â”‚  â”‚  3. Track wallets       â”‚  â”‚
                                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚                           â”‚
                                        â–¼                           â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ Ingestion Flush    â”‚   â”‚ Scheduler Flush    â”‚
                              â”‚ (every 5s)         â”‚   â”‚ (every 5s)         â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚                         â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚  compute_metrics()        â”‚
                                      â”‚  For each active mint:    â”‚
                                      â”‚  1. Compute RollingMetricsâ”‚
                                      â”‚  2. Detect signals        â”‚
                                      â”‚  3. Build aggregate state â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚  SQLite Database          â”‚
                                      â”‚  (rusqlite, Arc<Mutex<>>)â”‚
                                      â”‚                           â”‚
                                      â”‚  UPSERT token_aggregates  â”‚
                                      â”‚  INSERT token_signals     â”‚
                                      â”‚                           â”‚
                                      â”‚  âš ï¸ No WAL mode          â”‚
                                      â”‚  âš ï¸ No connection poolingâ”‚
                                      â”‚  âš ï¸ Single mutex lock    â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **B. FULL AUDIT OF DATA PATH**

### **1. Incoming Trade Path (4 Streamers)**

**Source:** `src/streamer_core/lib.rs` (TradeProcessor)

#### **Trade Detection Logic**
```rust
// From TransactionStatusMeta:
let sol_deltas = extract_sol_changes(&metadata.meta, &account_keys);
let token_deltas = extract_token_changes(&metadata.meta, &account_keys);

if let Some(trade_info) = extract_trade_info(&sol_deltas, &token_deltas, &account_keys) {
    // Build TradeEvent with:
    // - timestamp, signature, program_id, action (BUY/SELL)
    // - mint, sol_amount, token_amount, decimals
    // - user_account, discriminator
    
    // Path 1: Legacy JSONL write (blocking)
    writer.write(&event).await?;
    
    // Path 2: Pipeline channel (non-blocking)
    if let Some(tx) = &self.pipeline_tx {
        tx.try_send(pipeline_event)?; // Drops if full
    }
}
```

**Critical Issues:**
- âœ… **Correct:** Metadata-based extraction (no instruction decoding)
- âœ… **Correct:** try_send() is non-blocking (never stalls streamer)
- âŒ **PROBLEM:** JSONL write still happens (bloat accumulation continues)
- âŒ **PROBLEM:** No validation that pipeline channel is actually receiving

---

### **2. Dual-Channel Behavior**

**Legacy Path (JSONL):**
- **Active:** Always writes to `streams/{program}/events.jsonl`
- **Rotation:** Configured but never triggered (files grow indefinitely)
- **Purpose:** Historical compatibility (never intended as primary storage)
- **Impact:** âŒ **Causes database bloat** (files accumulate millions of trades)

**Pipeline Path (New):**
- **Active:** Only if `ENABLE_PIPELINE=true` in `pipeline_runtime.rs`
- **Channel:** `mpsc::channel::<TradeEvent>(10_000)` (bounded buffer)
- **Send:** `try_send()` - non-blocking, drops trades if full
- **Backpressure:** âŒ **Silent drops** when channel saturated (no logging until 1000 failures)

**Concurrent Behavior:**
- Both paths execute **simultaneously** for every trade
- Streamer never blocks on pipeline channel (try_send design)
- Pipeline failure does **not** affect JSONL writes
- âœ… **Good:** Parallel architecture (no runtime impact)
- âŒ **Bad:** No metrics on pipeline health (drop rate invisible)

---

### **3. Pipeline Ingestion Path**

**Entry:** `src/pipeline/ingestion.rs::start_pipeline_ingestion()`

```rust
loop {
    tokio::select! {
        // Path A: Receive trade from channel
        Some(trade) = rx.recv() => {
            let mut engine = engine.lock().unwrap();  // âš ï¸ LOCK CONTENTION
            engine.process_trade(trade);              // âš ï¸ SYNCHRONOUS
        }
        
        // Path B: Periodic flush (every 5s)
        _ = flush_timer.tick() => {
            flush_aggregates(&engine, &db_writer).await; // âš ï¸ HOLDS LOCK
        }
    }
}
```

**Critical Issues:**
- âš ï¸ **CONTENTION:** `Arc<Mutex<PipelineEngine>>` locked on every trade
- âš ï¸ **BLOCKING:** `process_trade()` is synchronous (eviction, HashMap ops)
- âš ï¸ **DUAL FLUSH:** Both ingestion loop AND scheduler loop flush (redundant work)
- âŒ **NO BATCHING:** Each trade processed individually (no transaction batching)

---

### **4. Pipeline Engine State Management**

**Core Structure:** `src/pipeline/engine.rs::PipelineEngine`

```rust
pub struct PipelineEngine {
    states: HashMap<String, TokenRollingState>,  // Per-token state
    last_bot_counts: HashMap<String, i32>,       // Bot history
    last_signal_state: HashMap<String, HashMap<SignalType, bool>>, // Dedup
    metadata_cache: HashMap<String, TokenMetadata>,  // Metadata
    // ...
}
```

**Per-Token State:** `src/pipeline/state.rs::TokenRollingState`

```rust
pub struct TokenRollingState {
    mint: String,
    trades_60s: Vec<TradeEvent>,         // âš ï¸ Unbounded growth risk
    trades_300s: Vec<TradeEvent>,        // âš ï¸ Unbounded growth risk
    trades_900s: Vec<TradeEvent>,        // âš ï¸ Unbounded growth risk
    unique_wallets_300s: HashSet<String>,
    bot_wallets_300s: HashSet<String>,
}
```

**Trade Processing:**
1. `process_trade(trade)` - Push to all 3 window vectors
2. `evict_old_trades(now)` - Retain trades within window range
3. `compute_rolling_metrics()` - Iterate over vectors, compute sums
4. `detect_signals()` - Apply threshold rules to metrics
5. `deduplicate_signals()` - Compare against last_signal_state

**Memory Management:**
- âœ… **Good:** Eviction runs on every trade (prevents unbounded growth)
- âš ï¸ **Risk:** High-volume tokens could hold thousands of trades per window
- âœ… **Good:** Bot detection is stateless (no accumulation)
- âŒ **PROBLEM:** No memory limits enforced (could OOM on sustained high-volume)

---

### **5. Scheduler Behavior**

**Flush Scheduler:** `src/pipeline/scheduler.rs::flush_scheduler_task()`

```rust
loop {
    timer.tick().await;  // Every 5 seconds
    
    let mints = engine.lock().unwrap().get_active_mints();  // âš ï¸ LOCK
    
    for mint in mints {
        let (metrics, signals, aggregate) = 
            engine.lock().unwrap().compute_metrics(mint, now);  // âš ï¸ LOCK PER MINT
        
        aggregates.push(aggregate);
        all_signals.extend(signals);
    }
    
    db_writer.write_aggregates(aggregates).await?;  // âš ï¸ SEQUENTIAL UPSERTS
    
    for signal in all_signals {
        db_writer.write_signal(signal).await?;  // âš ï¸ SEQUENTIAL INSERTS
    }
}
```

**Critical Issues:**
- âŒ **DUAL FLUSH:** Ingestion loop ALSO flushes every 5s (redundant)
- âš ï¸ **LOCK STORM:** One lock per mint, every 5 seconds
- âŒ **NO BATCHING:** Each aggregate/signal written individually
- âš ï¸ **BLOCKING:** Scheduler can stall ingestion if DB writes slow

**Price/Metadata Schedulers:**
- âŒ **NOT IMPLEMENTED:** Stub functions that sleep forever
- âœ… **Good:** Documented as "Phase 4.1" (intentional deferral)

---

### **6. Database Writes**

**Writer:** `src/pipeline/db.rs::SqliteAggregateWriter`

```rust
pub struct SqliteAggregateWriter {
    conn: Arc<Mutex<Connection>>,  // âš ï¸ Single connection, single mutex
}

async fn write_aggregates(&self, aggregates: Vec<AggregatedTokenState>) {
    let conn = self.conn.lock().unwrap();  // âš ï¸ EXCLUSIVE LOCK
    
    for agg in aggregates {  // âš ï¸ NO TRANSACTION
        conn.execute(r#"
            INSERT INTO token_aggregates (...) VALUES (...)
            ON CONFLICT(mint) DO UPDATE SET ...
        "#, params![...])?;
    }
    // âš ï¸ Lock held for entire loop duration
}

async fn write_signal(&self, signal: TokenSignal) {
    let conn = self.conn.lock().unwrap();  // âš ï¸ EXCLUSIVE LOCK
    
    let blocked = check_blocklist(&conn, &signal.mint, signal.created_at)?;
    if blocked { return Err(...); }
    
    conn.execute(r#"
        INSERT INTO token_signals (...) VALUES (...)
    "#, params![...])?;
}
```

**Critical Issues:**
- âŒ **NO WAL MODE:** SQLite in default rollback journal mode (write lock per transaction)
- âŒ **NO CONNECTION POOL:** Single connection shared by all threads
- âŒ **NO BATCHING:** Each aggregate/signal is a separate transaction
- âš ï¸ **LOCK CONTENTION:** Ingestion + scheduler + any readers compete for single mutex
- âŒ **SYNCHRONOUS I/O:** All writes block async tasks

**Schema Alignment:**
- âœ… **Perfect Match:** All `AggregatedTokenState` fields map to `token_aggregates` columns
- âœ… **Perfect Match:** All `TokenSignal` fields map to `token_signals` columns
- âœ… **Blocklist Check:** Correctly queries `mint_blocklist` before signal writes

---

## **C. MERMAID DIAGRAMS**

### **1. Component Diagram**

```mermaid
graph TB
    subgraph "Data Sources"
        GEYSER[Yellowstone gRPC]
    end
    
    subgraph "Streamers (4 binaries)"
        PS[PumpSwap Streamer]
        BS[BonkSwap Streamer]
        MS[Moonshot Streamer]
        JD[Jupiter DCA Streamer]
    end
    
    subgraph "Legacy Path (BLOAT)"
        JSONL1[streams/pumpswap/*.jsonl]
        JSONL2[streams/bonkswap/*.jsonl]
        JSONL3[streams/moonshot/*.jsonl]
        JSONL4[streams/jupiter_dca/*.jsonl]
    end
    
    subgraph "Pipeline Runtime"
        CHAN[mpsc Channel<br/>10k buffer]
        ING[Ingestion Loop<br/>tokio::select]
        ENG[PipelineEngine<br/>Arc&lt;Mutex&lt;&gt;&gt;]
        SCHED[Flush Scheduler<br/>5s interval]
    end
    
    subgraph "SQLite Database"
        AGG[token_aggregates<br/>UPSERT per mint]
        SIG[token_signals<br/>INSERT append-only]
        META[token_metadata<br/>Unused]
        BLOCK[mint_blocklist<br/>Read-only check]
    end
    
    GEYSER --> PS
    GEYSER --> BS
    GEYSER --> MS
    GEYSER --> JD
    
    PS -.Legacy.-> JSONL1
    BS -.Legacy.-> JSONL2
    MS -.Legacy.-> JSONL3
    JD -.Legacy.-> JSONL4
    
    PS -->|try_send| CHAN
    BS -->|try_send| CHAN
    MS -->|try_send| CHAN
    JD -->|try_send| CHAN
    
    CHAN --> ING
    ING -->|Lock<br/>process_trade| ENG
    ING -->|5s flush| ENG
    SCHED -->|5s flush| ENG
    
    ENG -->|write_aggregates| AGG
    ENG -->|write_signal| SIG
    SIG -.check blocklist.-> BLOCK
    
    style JSONL1 fill:#ff6b6b
    style JSONL2 fill:#ff6b6b
    style JSONL3 fill:#ff6b6b
    style JSONL4 fill:#ff6b6b
    style CHAN fill:#51cf66
    style ENG fill:#ffd43b
    style AGG fill:#339af0
    style SIG fill:#339af0
```

---

### **2. Sequence Diagram (Trade â†’ SQLite)**

```mermaid
sequenceDiagram
    participant Geyser as Yellowstone gRPC
    participant Streamer as PumpSwap Streamer
    participant JSONL as JSONL Writer
    participant Channel as mpsc Channel
    participant Ingestion as Ingestion Loop
    participant Engine as PipelineEngine
    participant DB as SQLite Writer
    participant SQLite as SQLite DB
    
    Geyser->>Streamer: Transaction (gRPC stream)
    Streamer->>Streamer: extract_trade_info()
    
    par Legacy Path
        Streamer->>JSONL: write(event)
        JSONL->>JSONL: Append to file (bloat++)
    and Pipeline Path
        Streamer->>Channel: try_send(event)
        Note over Channel: Non-blocking<br/>Drops if full
    end
    
    Channel->>Ingestion: rx.recv() await
    Ingestion->>Engine: Lock + process_trade()
    Engine->>Engine: Push to trades_60s/300s/900s
    Engine->>Engine: evict_old_trades()
    Ingestion-->>Engine: Unlock
    
    Note over Ingestion: Every 5 seconds
    Ingestion->>Engine: Lock + compute_metrics()
    Engine->>Engine: Iterate windows, sum metrics
    Engine->>Engine: detect_signals()
    Engine->>Engine: deduplicate_signals()
    Engine-->>Ingestion: (metrics, signals, aggregate)
    Ingestion-->>Engine: Unlock
    
    Ingestion->>DB: write_aggregates([agg])
    DB->>SQLite: Lock connection
    loop For each aggregate
        DB->>SQLite: INSERT ... ON CONFLICT UPDATE
    end
    DB-->>SQLite: Unlock connection
    
    Ingestion->>DB: write_signal(signal)
    DB->>SQLite: Lock connection
    DB->>SQLite: SELECT mint FROM mint_blocklist
    DB->>SQLite: INSERT INTO token_signals
    DB-->>SQLite: Unlock connection
```

---

### **3. Concurrency/Task Diagram**

```mermaid
graph TB
    subgraph "Streamer Processes (4 separate binaries)"
        T1[PumpSwap Streamer<br/>tokio runtime]
        T2[BonkSwap Streamer<br/>tokio runtime]
        T3[Moonshot Streamer<br/>tokio runtime]
        T4[Jupiter DCA Streamer<br/>tokio runtime]
    end
    
    subgraph "Pipeline Runtime (single binary)"
        MAIN[main() tokio runtime]
        
        subgraph "Spawned Tasks"
            ING[Ingestion Task<br/>tokio::spawn]
            FLUSH[Flush Scheduler<br/>tokio::spawn]
            PRICE[Price Scheduler<br/>tokio::spawn<br/>STUB]
            META[Metadata Scheduler<br/>tokio::spawn<br/>STUB]
        end
        
        subgraph "Shared State"
            ENG[Arc&lt;Mutex&lt;PipelineEngine&gt;&gt;]
            DB[Arc&lt;dyn AggregateDbWriter&gt;]
        end
    end
    
    subgraph "Channels"
        CHAN[mpsc::channel<br/>10k buffer]
    end
    
    T1 -.try_send.-> CHAN
    T2 -.try_send.-> CHAN
    T3 -.try_send.-> CHAN
    T4 -.try_send.-> CHAN
    
    MAIN --> ING
    MAIN --> FLUSH
    MAIN --> PRICE
    MAIN --> META
    
    CHAN --> ING
    
    ING -.Lock.-> ENG
    FLUSH -.Lock.-> ENG
    
    ING --> DB
    FLUSH --> DB
    
    DB -.Lock.-> SQLITE[(SQLite<br/>Arc&lt;Mutex&lt;Connection&gt;&gt;)]
    
    style CHAN fill:#51cf66
    style ENG fill:#ffd43b
    style DB fill:#339af0
    style SQLITE fill:#339af0
    style PRICE fill:#ff6b6b
    style META fill:#ff6b6b
```

---

## **D. PROBLEMS TABLE**

| # | Category | Problem | Severity | Impact | Root Cause |
|---|----------|---------|----------|--------|------------|
| **1** | **Data Flow** | **JSONL files still accumulating** | ğŸ”´ **CRITICAL** | Database bloat continues unabated | Dual-channel design preserves legacy path without deprecation plan |
| **2** | **Business Goal** | **DCA correlation NOT implemented** | ğŸ”´ **CRITICAL** | System cannot detect "conviction signals" (stated goal) | Pipeline treats all 4 streams identicallyâ€”no cross-stream correlation |
| **3** | **Concurrency** | **Single Mutex<PipelineEngine>** | ğŸŸ  **HIGH** | Lock contention on every trade + periodic flushes | All async tasks compete for same lock |
| **4** | **Database** | **No WAL mode** | ğŸŸ  **HIGH** | Write lock on every transaction blocks readers | SQLite defaults to rollback journal mode |
| **5** | **Database** | **No connection pooling** | ğŸŸ  **HIGH** | Single connection = serial writes only | Arc<Mutex<Connection>> design pattern |
| **6** | **Database** | **No transaction batching** | ğŸŸ  **HIGH** | Hundreds of individual transactions per flush | Each aggregate/signal written separately |
| **7** | **Scheduler** | **Dual flush redundancy** | ğŸŸ  **HIGH** | Ingestion + scheduler both flush every 5s | Duplicate work, wasted CPU/DB writes |
| **8** | **Backpressure** | **Silent trade drops** | ğŸŸ¡ **MEDIUM** | Lost data when channel full, no metrics | try_send() with 1000-failure throttled logging |
| **9** | **Memory** | **Unbounded rolling state** | ğŸŸ¡ **MEDIUM** | High-volume tokens could OOM | Vec<TradeEvent> per window, no cap enforced |
| **10** | **Architecture** | **Unused windows.rs module** | ğŸŸ¡ **MEDIUM** | 206 lines of dead code | TimeWindow abstraction never used |
| **11** | **Architecture** | **Stubbed blocklist.rs** | ğŸŸ¡ **MEDIUM** | 81 lines of unimplemented trait | Planned but not activated |
| **12** | **Schema** | **token_metadata unused** | ğŸŸ¡ **MEDIUM** | Metadata cache in memory, never persisted/read | No integration with metadata scheduler (stub) |
| **13** | **Schema** | **Price fields always NULL** | ğŸŸ¡ **MEDIUM** | price_usd, price_sol, market_cap_usd never populated | Price scheduler not implemented |
| **14** | **Testing** | **No integration tests for pipeline** | ğŸŸ¢ **LOW** | Only unit tests, no end-to-end validation | test_dual_channel_streamer.rs exists but minimal |
| **15** | **Observability** | **No metrics on pipeline health** | ğŸŸ¢ **LOW** | Cannot monitor drop rate, latency, throughput | Only log-based metrics (every 10k trades) |

---

## **E. ROOT CAUSE ANALYSIS**

### **1. Database Bloat**

**Symptom:** JSONL files in `streams/` directories growing indefinitely

**Root Cause:**
- **Dual-channel architecture** preserves legacy JSONL path "for compatibility"
- Streamers **always write JSONL** regardless of pipeline enablement
- JSONL rotation configured but **never triggered** (bug or misconfiguration)
- No deprecation plan for legacy path

**Contributing Factors:**
- `pipeline_tx: Option<>` design implies JSONL is primary, pipeline is optional
- No environment variable to disable JSONL writes
- No documentation on migration path from JSONL to pipeline

**Solution Path:**
1. Add `DISABLE_JSONL=true` environment variable
2. Make pipeline the primary path (JSONL opt-in for debugging only)
3. Delete existing JSONL files or move to archive storage
4. Document migration in AGENTS.md

---

### **2. DCA Correlation Missing**

**Symptom:** Jupiter DCA trades flow through pipeline but are never correlated with other streams

**Root Cause:**
- **Single-token processing model:** PipelineEngine processes each mint in isolation
- **No cross-mint correlation:** No mechanism to match PumpSwap BUYs with DCA activity
- **Signal detection is per-token:** BREAKOUT/SURGE/FOCUSED only look at one token's metrics

**Expected Implementation (from business goal):**
```rust
// MISSING: Correlation Engine
for mint in active_mints {
    let pumpswap_buys = get_trades_for_program(mint, "PumpSwap", TradeDirection::Buy);
    let dca_fills = get_trades_for_program(mint, "JupiterDCA", TradeDirection::Buy);
    
    // Check for temporal overlap (Â±60s window)
    let dca_overlap_pct = compute_overlap(pumpswap_buys, dca_fills, 60);
    
    if dca_overlap_pct > 0.25 {  // 25% threshold
        emit_signal(TokenSignal::DcaConviction { overlap: dca_overlap_pct });
    }
}
```

**Contributing Factors:**
- TradeEvent has `source_program` field but it's never used for filtering
- TokenRollingState doesn't separate trades by source
- No aggregator_core/ module in this branch (exists separately in main?)

**Solution Path:**
1. Add `trades_by_program: HashMap<String, Vec<TradeEvent>>` to TokenRollingState
2. Implement DcaCorrelationDetector in signals.rs
3. Add DCA_CONVICTION signal type
4. Add correlation tests

---

### **3. Ingestion Backpressure**

**Symptom:** Channel buffer (10k trades) can saturate under high load, causing silent drops

**Root Cause:**
- **Bounded channel** with `try_send()` non-blocking design
- **No flow control:** Streamers never slow down based on pipeline capacity
- **No metrics:** Drop rate invisible until 1000 failures accumulate

**Contributing Factors:**
- `tokio::select!` design processes one trade at a time (no batching)
- `process_trade()` holds lock for duration of trade processing
- Flush operations hold lock for all active mints (blocks ingestion)

**Solution Path:**
1. Add channel metrics: `channel.len()`, `total_drops`, `drop_rate`
2. Implement batched ingestion: `rx.recv_many(batch, 100)` instead of `rx.recv()`
3. Add backpressure signal: log warning when channel >80% full
4. Consider unbounded channel with memory limits

---

### **4. SQLite Write Performance**

**Symptom:** Single-threaded writes, no batching, no WAL mode

**Root Cause:**
- **Arc<Mutex<Connection>>** design enforces serial access
- **No transaction scope:** Each write is auto-commit transaction
- **Default journal mode:** Rollback journal requires fsync per transaction

**Contributing Factors:**
- `async fn write_aggregates()` uses `await` but is synchronous I/O
- No connection pool library (e.g., `sqlx`, `r2d2`)
- rusqlite is synchronous library wrapped in async function

**Solution Path:**
1. Enable WAL mode: `PRAGMA journal_mode=WAL`
2. Batch writes in single transaction:
   ```rust
   let tx = conn.transaction()?;
   for agg in aggregates {
       tx.execute(...)?;
   }
   tx.commit()?;
   ```
3. Consider dedicated write thread with crossbeam channel
4. Or switch to `sqlx` for true async I/O

---

## **F. RECOMMENDED ARCHITECTURAL CORRECTIONS**

### **Priority 1: Fix Database Bloat (IMMEDIATE)**

1. **Disable JSONL writes by default**
   ```rust
   // In streamer_core/lib.rs
   if env::var("ENABLE_JSONL").unwrap_or("false".to_string()) == "true" {
       writer.write(&event).await?;
   }
   ```

2. **Make pipeline the primary path**
   ```rust
   // pipeline_tx should not be Option
   pub struct StreamerConfig {
       pub pipeline_tx: mpsc::Sender<TradeEvent>,  // Required, not optional
   }
   ```

3. **Archive/delete existing JSONL files**
   ```bash
   mkdir -p archive/
   mv streams/*/*.jsonl archive/
   ```

4. **Update AGENTS.md to reflect new architecture**

---

### **Priority 2: Implement DCA Correlation (CRITICAL FOR BUSINESS GOAL)**

1. **Add per-program trade separation**
   ```rust
   pub struct TokenRollingState {
       trades_by_program: HashMap<String, Vec<TradeEvent>>,  // NEW
       // ... existing fields
   }
   ```

2. **Implement correlation detector**
   ```rust
   // In signals.rs
   pub enum SignalType {
       // ... existing
       DcaConviction,  // NEW: PumpSwap buys + DCA fills overlap
   }
   
   fn detect_dca_correlation(
       pumpswap_trades: &[TradeEvent],
       dca_trades: &[TradeEvent],
       window_secs: i64,
   ) -> Option<TokenSignal> {
       // Temporal overlap detection (Â±60s)
       let overlap_pct = compute_temporal_overlap(pumpswap_trades, dca_trades, window_secs);
       
       if overlap_pct > 0.25 {
           return Some(TokenSignal::new(...)
               .with_details(format!(r#"{{"dca_overlap_pct":{}}}"#, overlap_pct)));
       }
       None
   }
   ```

3. **Integrate into pipeline engine**
   ```rust
   // In engine.rs::compute_metrics()
   let dca_signal = detect_dca_correlation(
       state.get_trades_for_program("PumpSwap"),
       state.get_trades_for_program("JupiterDCA"),
       60,
   );
   if let Some(sig) = dca_signal {
       signals.push(sig);
   }
   ```

---

### **Priority 3: Fix Concurrency Bottlenecks (HIGH)**

1. **Enable SQLite WAL mode**
   ```rust
   // In db.rs::SqliteAggregateWriter::new()
   conn.pragma_update(None, "journal_mode", "WAL")?;
   log::info!("âœ… SQLite WAL mode enabled");
   ```

2. **Batch database writes**
   ```rust
   async fn write_aggregates(&self, aggregates: Vec<AggregatedTokenState>) {
       let conn = self.conn.lock().unwrap();
       let tx = conn.transaction()?;  // BEGIN TRANSACTION
       
       for agg in aggregates {
           tx.execute(...)?;
       }
       
       tx.commit()?;  // COMMIT (single fsync)
   }
   ```

3. **Remove duplicate flush scheduler**
   ```rust
   // In pipeline_runtime.rs
   // DELETE THIS TASK:
   // tokio::spawn(flush_scheduler_task(...));
   
   // Keep only ingestion flush (every 5s is sufficient)
   ```

4. **Add channel metrics**
   ```rust
   // In ingestion.rs
   let capacity = rx.capacity();
   let current_len = rx.len();
   let utilization = current_len as f64 / capacity as f64;
   
   if utilization > 0.8 {
       log::warn!("âš ï¸  Channel {}% full ({} / {})", utilization * 100.0, current_len, capacity);
   }
   ```

---

### **Priority 4: Clean Up Dead Code (MEDIUM)**

1. **Delete unused modules**
   - `src/pipeline/windows.rs` (206 lines, never used)
   - `src/pipeline/blocklist.rs` (81 lines, stub only)

2. **Document unimplemented features**
   ```rust
   // In scheduler.rs
   // REMOVED: price_scheduler_task (not implemented in Phase 4)
   // REMOVED: metadata_scheduler_task (not implemented in Phase 4)
   // TODO: Phase 4.1 - Add price/metadata enrichment
   ```

3. **Remove unused schema tables**
   - `token_metadata` table (never written to)
   - Or implement metadata scheduler

---

### **Priority 5: Add Observability (LOW)**

1. **Channel metrics**
   - Drop rate (trades/sec lost)
   - Channel utilization (%)
   - Ingestion latency (ms)

2. **Pipeline metrics**
   - Active mints count
   - Trades processed/sec
   - Flush duration (ms)
   - DB write latency (ms)

3. **Signal metrics**
   - Signals detected/min (by type)
   - Blocklist rejections/min
   - Deduplication rate (%)

---

## **G. CONFIDENCE SCORES (0-100)**

### **1. Correctness: 65/100** ğŸŸ¡

**Positive:**
- âœ… Schema alignment is perfect (types.rs â†” SQL)
- âœ… Blocklist checks are correctly implemented
- âœ… Signal deduplication works as designed
- âœ… Rolling window eviction prevents memory leaks
- âœ… Bot detection heuristics are sound

**Negative:**
- âŒ **Business goal NOT met** (DCA correlation missing)
- âŒ JSONL bloat continues (legacy path still active)
- âŒ Unbounded memory growth possible (high-volume tokens)
- âš ï¸ Silent trade drops (no backpressure handling)

**Rating Justification:** System works as coded, but doesn't solve the stated problem.

---

### **2. Performance: 45/100** ğŸ”´

**Bottlenecks:**
- âŒ **Single Mutex<PipelineEngine>** (all async tasks contend)
- âŒ **No WAL mode** (SQLite write locks block readers)
- âŒ **No connection pooling** (single connection = serial writes)
- âŒ **No batching** (hundreds of transactions per flush)
- âŒ **Dual flush** (ingestion + scheduler both flush every 5s)

**Strengths:**
- âœ… try_send() never blocks streamers
- âœ… Eviction is O(n) with small n (only trades in window)
- âœ… Bot detection is O(tÂ²) but typically t < 100

**Rating Justification:** Will struggle under production load (>1000 trades/sec).

---

### **3. Reliability: 55/100** ğŸŸ¡

**Risks:**
- âŒ **Silent data loss** (channel drops)
- âŒ **OOM risk** (unbounded rolling state on high-volume tokens)
- âš ï¸ **Lock contention** (could cause ingestion stalls)
- âš ï¸ **No recovery** (pipeline crash loses in-memory state)

**Strengths:**
- âœ… Streamers never crash due to pipeline issues (try_send)
- âœ… Database writes are atomic (per-transaction)
- âœ… Blocklist prevents bad data from entering signals table

**Rating Justification:** Works in low-load scenarios, fragile at scale.

---

### **4. Maintainability: 70/100** ğŸŸ¢

**Positive:**
- âœ… Excellent documentation (every module has doc comments)
- âœ… Comprehensive unit tests (especially state.rs, engine.rs)
- âœ… Clear separation of concerns (types, state, signals, db)
- âœ… Schema-first design (SQL files as source of truth)

**Negative:**
- âŒ Dead code (windows.rs, blocklist.rs)
- âŒ TODOs scattered throughout (30+ instances)
- âš ï¸ Dual architecture (JSONL + pipeline) increases complexity

**Rating Justification:** Well-structured code, but unfinished features create technical debt.

---

### **5. Alignment with Business Goal: 30/100** ğŸ”´

**Business Goal:** *"Prevent database bloat and focus solely on volume from PumpSwap, BonkSwap, Moonshot, matched with Jupiter DCA activity, because that combination provides a strong conviction signal."*

**Analysis:**
- âŒ **Database bloat NOT fixed** (JSONL still accumulating)
- âŒ **DCA correlation NOT implemented** (no cross-stream analysis)
- âœ… **Volume tracking works** (rolling aggregates are correct)
- âœ… **Signal detection works** (BREAKOUT, SURGE, FOCUSED all functional)
- âš ï¸ **DCA data flows through** (but never used for correlation)

**Gap Analysis:**
- Pipeline is **infrastructure-complete** but **business-logic-incomplete**
- System can **detect activity** but not **conviction**
- DCA trades are collected but **never compared** to spot trading

**Rating Justification:** Solid foundation, but core feature missing.

---

## **FINAL ASSESSMENT**

### **Overall Architecture Grade: C+ (70/100)**

**Strengths:**
- âœ… **Rock-solid foundation:** Schema design, rolling windows, signal detection
- âœ… **Dual-channel safety:** Pipeline never impacts streamer stability
- âœ… **Comprehensive testing:** Unit tests cover edge cases
- âœ… **Clean separation:** Pipeline is isolated from legacy code

**Critical Gaps:**
- âŒ **Business goal unmet:** DCA correlation not implemented
- âŒ **Bloat continues:** JSONL path still active
- âŒ **Performance issues:** Lock contention, no batching, no WAL

### **Recommendation: DO NOT MERGE without addressing Priority 1-3**

**Required Before Merge:**
1. Disable JSONL writes (or add migration plan)
2. Implement DCA correlation (core business requirement)
3. Enable SQLite WAL mode + batch writes

**Nice-to-Have (can defer):**
4. Remove dead code (windows.rs, blocklist.rs)
5. Add observability metrics
6. Implement price/metadata enrichment

### **Estimated Effort:**
- **P1 (JSONL disable):** 2 hours
- **P2 (DCA correlation):** 8-16 hours
- **P3 (WAL + batching):** 4 hours
- **Total:** 2-3 days for production-ready system

---

## **APPENDIX: CODE QUALITY OBSERVATIONS**

### **Excellent Practices**
- Schema-first design (SQL as source of truth)
- Comprehensive doc comments (every function documented)
- Strong typing (no `unwrap()` without error handling)
- Builder pattern for signal construction
- Extensive unit tests (>20 test functions in state.rs alone)

### **Areas for Improvement**
- TODO comments should be GitHub issues
- Magic numbers need constants (e.g., 0.25 threshold for BREAKOUT)
- Error handling uses `Box<dyn Error>` (consider typed errors)
- Synchronous I/O wrapped in async functions (confusing)
- No CI/CD integration tests

---

**End of Architectural Review**
